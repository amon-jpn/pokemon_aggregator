import feedparser
from feedgen.feed import FeedGenerator
from datetime import datetime, timezone
import difflib
import time

# è¨­å®š
RSS_SOURCES = [
    "https://game.watch.impress.co.jp/data/rss/1.0/gmw/feed.rdf",
    "https://www.ndw.jp/feed/",
    "https://www.4gamer.net/publisher/013/P01387/contents.xml",
    "https://hobby.watch.impress.co.jp/data/rss/1.0/hbw/feed.rdf"
]
OUTPUT_FILE = "pokemon_news.xml"
KEYWORD = "ãƒã‚±ãƒ¢ãƒ³"
SIMILARITY_THRESHOLD = 0.85  # ãƒ¬ãƒ™ãƒ«3: é¡ä¼¼åº¦85%ä»¥ä¸Šã‚’é‡è¤‡ã¨åˆ¤å®š

def get_similarity(a, b):
    """ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    return difflib.SequenceMatcher(None, a, b).ratio()

def main():
    all_entries = []
    
    # 1. å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¨˜äº‹ã‚’å–å¾—
    for url in RSS_SOURCES:
        print(f"ğŸ“¡ å–å¾—ä¸­: {url}")
        feed = feedparser.parse(url)
        for entry in feed.entries:
            title = entry.get('title', '')
            summary = entry.get('summary', entry.get('description', ''))
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œãƒã‚±ãƒ¢ãƒ³ã€ãŒå«ã¾ã‚Œã‚‹ã‹åˆ¤å®š
            if KEYWORD in title or KEYWORD in summary:
                # æŠ•ç¨¿æ—¥æ™‚ã‚’å–å¾—
                pub_date = None
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_date = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=timezone.utc)
                
                all_entries.append({
                    'title': title,
                    'link': entry.link,
                    'date': pub_date,
                    'summary': summary
                })

    # 2. é‡è¤‡æ’é™¤ï¼ˆãƒ¬ãƒ™ãƒ«3ï¼šé¡ä¼¼åº¦åˆ¤å®šï¼‰
    unique_entries = []
    for entry in all_entries:
        is_duplicate = False
        for existing in unique_entries:
            # ã‚¿ã‚¤ãƒˆãƒ«ã®é¡ä¼¼åº¦ã‚’ãƒã‚§ãƒƒã‚¯
            if get_similarity(entry['title'], existing['title']) > SIMILARITY_THRESHOLD:
                is_duplicate = True
                break
        
        if not is_duplicate:
            unique_entries.append(entry)

    # 3. æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    unique_entries.sort(key=lambda x: x['date'] if x['date'] else datetime.min.replace(tzinfo=timezone.utc), reverse=True)

    # 4. æ–°ã—ã„RSSã‚’ç”Ÿæˆ
    fg = FeedGenerator()
    fg.title("ãƒã‚±ãƒ¢ãƒ³æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚")
    fg.description("è¤‡æ•°ã‚µã‚¤ãƒˆã‹ã‚‰ãƒã‚±ãƒ¢ãƒ³é–¢é€£ã®è¨˜äº‹ã‚’é‡è¤‡ãªãé›†ç´„")
    fg.link(href="https://github.com/", rel="alternate")
    fg.language("ja")
    fg.lastBuildDate(datetime.now(timezone.utc))

    for item in unique_entries:
        fe = fg.add_entry()
        fe.title(item['title'])
        fe.link(href=item['link'])
        fe.description(item['summary'])
        if item['date']:
            fe.pubDate(item['date'])

    fg.rss_file(OUTPUT_FILE)
    print(f"âœ… å®Œäº†: {len(unique_entries)}ä»¶ã®è¨˜äº‹ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
